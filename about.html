<!DOCTYPE html>
<html>
  <head>
    <title>About Project</title>
    <link rel="stylesheet" type="text/css" href="style.css">
  </head>

  <body>
    <div class="menu-bar">
      <a class="menu-item" href="about.html">ABOUT PROJECT</a>
      <a class="menu-item" href="who.html">WHO WE ARE</a>
      <a class="menu-item" href="see.html">SEE OUR WORK</a>
      <a class="menu-item" href="Try.html">TRY PROGRAM</a>
    </div>
    <h1>Data Analysis Hackathon Project üë©‚Äçüíª</h1>
    <h2>Analyzing Misinformation in News using NLP and Data Visualization</h2>
    <p>This project was created for the CANIS Data Analysis Hackathon. The task was to create compelling data visualizations that would help others understand the survey results in a meaningful way. The dataset used in this project is available on Kaggle through this <a href="https://www.kaggle.com/datasets/stevenpeutz/misinformation-fake-news-text-dataset-79k?resource=download">link</a>.</p>

    <h2>Project Purpose ‚õ≥</h2>
    <p> The purpose of this project is to analyze a dataset of news articles and identify the words that are most frequently used in true and fake news. Our goal is to gain insights into the language patterns that are associated with fake news and to develop techniques for detecting and combating misinformation.  <br>
        To achieve this, we will perform data analysis and NLP techniques on the dataset, extract meaningful insights, and create data visualizations to present our findings in an understandable and meaningful way.  <br>
        By identifying the key language features of fake news, we hope to contribute to the development of more effective strategies for combating the spread of misinformation and promoting the dissemination of accurate and reliable information.</p>

        <h2>Project Overview üëì</h2>
        <p>The project involves data analysis of the misinformation fake news text dataset. The project includes the following steps: </p>
        <ul>
          <li>Preprocessing the dataset by cleaning, formatting, and transforming the data into a suitable format for analysis.</li>
          <li>Performing Natural Language Processing (NLP) techniques, such as tokenization, stemming, and lemmatization, to extract meaningful information from the text data.</li>
          <li>Identifying and removing stop words and other irrelevant information from the dataset.</li>
          <li>Visualizing the results of the analysis using various tools, such as charts, graphs, and interactive dashboards, to make the insights more understandable and accessible to users.</li>
          <li>Developing a web-based platform to present the findings of the analysis and enable users to interact with the data and explore the results in more detail.</li>
        </ul>
        
  <div style="background-color: #f2f2f2; padding: 10px; margin-left: 20px;">
    <h3>Dependencies for Python Program üì¶</h3>
    <p>The code for this project is written in Python and requires the following dependencies:</p>
    <ul>
        <li>pandas</li>
        <li>nltk</li>
        <li>textblob</li>
        <li>matplotlib</li>
        <li>wordcloud</li>
    </ul>
    <p>To install the dependencies, run the following commands:</p>
    <pre>
pip install pandas
pip install nltk
pip install textblob
pip install matplotlib
    </pre>

  </div>
  
  <br>

  <p>
    After Python script that simplified the datasets based on word frequency. From there, our team of data analysts used advanced techniques and R code to analyze the data and identify patterns that could distinguish between fake and true news.<br><br>

To create our fake news detector, we collected all possible word sets that were likely to be associated with fake news and used this data to make the detector. Now, if a news article contains a certain number of these words, our detector can quickly flag it as fake news. It's like having a trusty assistant by our side, helping us navigate the murky waters of information overload and stay vigilant against the spread of false information! üïµÔ∏è‚Äç‚ôÄÔ∏èüì∞
  </p>


  </body>
</html>
